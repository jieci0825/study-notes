# HTTP各版本差异

## HTTP1.0

### 无法复用连接

HTTP1.0 为每个请求单独开一个 TCP 连接

<img src="http://cos.coderjc.cn/blog/image-20240418101644533.png" alt="image-20240418101644533" style="zoom:50%;" />

由于每个请求都是独立的连接，因此会带来下面的问题：

1. 连接的建立和销毁都会占用服务器和客户端的资源，造成内存资源的浪费
2. 连接的建立和销毁都会消耗时间，造成响应时间的浪费
3. 无法充分利用带宽，造成带宽资源的浪费

> TCP 协议的特点**慢启动**，即一开始传输的数据量少，一段时间之后达到传输的峰值，而上面这种做法，会导致大量的请求在 TCP 达到传输峰值前就被销毁

### 队头阻塞

即请求只能上一个结束才能进行下一个，无法并行请求，效率非常低下

## HTTP1.1

### 长连接

为了解决 HTTP1.0 的问题，HTTP1.1 默认开启长连接，既让同一个 TCP 连接服务于多个请求-响应

<img src="http://cos.coderjc.cn/blog/image-20240418103450645.png" alt="image-20240418103450645" style="zoom:50%;" />

在这种情况下，多次请求响应可以共享同一个 TCP 连接，这不仅减少了 TCP 的握手和挥手时间，同时可以充分利用 TCP 慢启动的特点，有效利用带宽

> 实际上，在 HTTP1.0 后期，官方虽然没有官方标准，但是开发者都慢慢形成了一个共识：
>
> **只要请求头中包含 Connection: keep-alive，就表示客户端希望开启长连接，希望服务器响应后不要关闭 TCP 连接，如果服务器认可这一行为，那可以保持 TCP 连接**

当需要的时候，任何一方都可以关闭 TCP 连接

> 连接关闭的情况主要有三种：
>
> 1. 客户端再某一次请求中设置了 Connection: close，服务器收到此请求之后，响应立即结束关闭 TCP
> 2. 在没有请求时，客户端会不断对夫妻进行心跳检测（一般每隔1秒）。一旦心跳检测停止，立即关闭 TCP
> 3. 当客户端长时间没有心的请求达到服务器，服务器会主动关闭 TCP，运维人员可以设置该时间

由于一个 TCP 连接可以承载多次请求响应，并在一段时间内不会断开，因此这种连接称之为长连接

### 管道化和队头阻塞

HTTP1.1 云讯在响应达到之前发送下一个请求，这样就可以大幅度缩减带宽限制时间

**但是这样就会在存在队头阻塞的问题**

<img src="http://cos.coderjc.cn/blog/image-20240418120134487.png" alt="image-20240418120134487" style="zoom:50%;" />

在上图中的管道化中，第一个请求耗时长，第二个请求耗时短，但是是第一个和第二个请求直接一起发出去了，但是请求2早就完成了，请求1还没完成，但是请求2的响应需要等请求1响应之后才能返回，请求2就被请求1阻塞了，这种情也叫做**队头阻塞**

由于多个请求使用的是同一个 TCP 连接，**服务器必须按照请求到达的顺序进行响应**

于是，导致了一些后发送的请求，无法在处理完成后及时响应，产生了等待的时间，而这段时间的带宽是空闲的，这就造成了带宽的浪费

队头阻塞**虽然发生在服务器**，但是这个问题的根源是客户端无法知晓服务器的响应是针对那个请求的

正是由于存在队头阻塞的问题，我们通常使用下面的手段进行优化：

- 通过减少文件数量，从而减少队友阻塞的几率

- 通过开辟多个 TCP 连接，实现真正的、有缺陷的并行传输

  > 浏览器会根据情况，为打开的页面自动开启 TCP 连接，对于同一个域名的连接最多6个，如果要突破这个限制，就需要吧资源放到不同的域中

**然而管道化并非一个成功的模型，它带来的队头阻塞会造成非常多的问题，所以现代浏览器默认是关闭这种模式的**

## HTTP2.0

> HTTP2.O 必须运行在加密协议之上

### 二进制分帧

HTTP2.0 可以允许以更小的单源传输数据，每个传输单元称之为**帧**，而每一个请求或响应的完整数据称之为流，每个流有自己的编号，每个帧会记录所有的流

比如，服务器连续提到了客户端的两个请求，一个请求 js，一个请求 css

js文件内容如下：

~~~js
function foo(){}
function bar(){}
~~~

css文件如下：

~~~css
.container{}
.box{}
~~~

最终形成的帧可能如下：

<img src="http://cos.coderjc.cn/blog/image-20240418142609446.png" alt="image-20240418142609446" style="zoom:50%;" />

这只是举例，实际可能内容过小的，一个帧就传输了

可以看出，每个帧都带了一个头部，记录了流的 ID，这样就可以准确知道这一帧数据属于那个流的

基于这种模式就可以实现请求响应完成了就下发，不会出现队头阻塞的问题，因为可以知道自己属于那个流，也就知道属于那个请求的响应，实现了真正的**多路复用**

不仅如此，由于传输是是以帧为单元传输的，无论响应还是请求，都可以实现并发请求，即不同的传输可以交替进行

由于进行了分帧，还可以设置传输优先级

### 头部压缩

HTTP2.0 之前，所有的消息头都是以字符形式完整传输的

可实际上，大部分头部信息都有很多的重复

为了解决这一问题，HTTP2.0 使用头部压缩来减少消息头的体积

<img src="http://cos.coderjc.cn/blog/image-20240418145329692.png" alt="image-20240418145329692" style="zoom:50%;" />

对于两张表都没有的头部，则使用 Huffman 编码压缩后进行传输，同时添加到动态表中

### 服务器推

HTTP2.0 允许在客户端没有主动请求的情况下，服务器预先吧资源推送给客户端

当客户端后续要请求资源时，则自动从之前推送的资源中寻找

